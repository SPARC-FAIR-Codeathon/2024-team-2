{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Tutorial 5: Assembling a workflow automatically using sparc-assemble\n",
    "This tutorial shows how, given a specific request, sparc-assemble can automatically retrieve all the possible workflows that can be used to generate the desired output. The user can then select the most appropriate workflow for their needs. The chosen workflow is saved in the cwl format. "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "49baf1f954efbc97"
  },
  {
   "cell_type": "markdown",
   "id": "466d223649b669d7",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Prerequisites\n",
    "A populated knowledge graph is required to assemble workflows. Please see tutorial 2. Two examples are provided under resources folder.\n",
    "Moreover, in order to provide a cwl description of the workflow, each tool should have a cwl file associated with it. For ease, having both json and cwl file in a '/tools' folder is helpful. Please see tutorial 1 for more details. Example tools are provided under resources/tools folder.\n",
    "\n",
    "Open jupyter through my binder (https://mybinder.org/v2/gh/jupyter/docker-stacks/main?urlpath=lab/tree/README.ipynb) and manually add the resources (don't forget the tools under resources/tools), scripts and ipynb files to the jupyter environment. Make sure to have the same structure as the one provided in the repository under tutorials/tutorial_5_assemble_workflow.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Note\n",
    "This code requires user interaction through python prompting. This feature is not compatible with the use of jupyter notebook. Hence, the user is required to run the command in a terminal (file -> new -> terminal). The different steps are detailed below. "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "476ebb6175b66e05"
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "## Terminal command lines\n",
    "First, install the requirements. You only need to install sparc-assemble package in the terminal (this might take a few minutes):"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2095ae2a3c223399"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b6dccd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install sparc-assemble"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Make sure the ls command returns the following structure: \n",
    "assemble_workflow.py  resources  tutorial_5_assemble_workflow.ipynb \n",
    "with resources containing the tools and example knowledge graphs."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cee52d3465bc52a7"
  },
  {
   "cell_type": "markdown",
   "id": "ae01bd43",
   "metadata": {},
   "source": [
    "Then, run the script in the terminal:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edd0c162",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "python assemble_workflow.py --kg_path <path_to_your_knowledge_graph> --tools_path <path_to_your_tools_folder>"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "The arguments required are KG_path which is the path to your knowledge graph owl file and tools_path which is the path to your tools folder containing the json and cwl files for all the tools. Bear in mind that you are running the script from examples/example_assemble_workflow .\n",
    "\n",
    "Please see example section below for details on how to run the script for each example."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "96c96c8261a5f578"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Examples\n",
    "**Example 1**:\n",
    "The first example is based on a knowledge graph containing tools only. The tools are associated with json and cwl files (see tutorial_assemble_workflow/resources). In that example we show how to assemble a workflow to derive the parameter y_file from a dataset.\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1a8fb0f8ede85008"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "python assemble_workflow.py --kg_path resources/kg_example_1.owl --tools_path resources/tools"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b4648412dee99bd9"
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Example 2**:\n",
    "The second example serves as an introduction to the discovery functionality offered by the tool. In this case, the knowledge graph contains tools and models. The tool and model are associated with json files but not cwl files. In that example we show how to navigate the available workflow and highlight the inputs available from a dtaset and the inputs that are missing to derive the parameter of interest 'vm.Membrane/V'."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b53ffef22a16b7e8"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "python assemble_workflow.py --kg_path resources/kg_example_2.owl"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "18e10f7050c4fc8d"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Steps\n",
    "\n",
    "**1. Enter request**\n",
    "\n",
    "As soon as you run the command line, you will be prompted to specify which parameter you would like to derive. If you have followed the previous workflow you should have an idea of what are the outputs available in the knowledge graph. In case you do not have any idea, you can give it a try; you will be prompted with the available choice in case your try does not return any match. \n",
    "Hint: Example1: type y_file. Example2: type time. \n",
    "\n",
    "The outputs search is flexible and uses natural language processing to find the similarity between your request and the available outputs. If no match are found, you will be prompted with the available outputs, and you can specify a new request using this information.\n",
    "\n",
    "Note: At this stage, the request can only be a single parameter.\n",
    "\n",
    "\n",
    "**2. Choose your preferred workflow**\n",
    "\n",
    "Once you have validated your request, the knowledge graph is queried in order to return every possible workflows that allow deriving your requested parameter. You will see two nested lists. The first level corresponds to the methods that can compute your requested parameter directly. You can therefore choose which method you want to use to derive your parameter. The second level corresponds to all the possible workflows using the method in question as the last step. These workflows allow you to navigate the different combination available to derive your parameter of interest and make your choice depending on the input availability. Indeed, the 'Input' key highlight the required inputs for each workflow followed by a succession of inputs -> tool -> outputs (i.e., steps) with the required workflow inputs appearing in bold.\n",
    "\n",
    "Attention: provide the number of the method of your choice first, and then the number of the workflow of your choice under the chosen method. \n",
    "Hint: Example 1: enter 1, then 2. \n",
    "Example 2 stop with the display of the options as cwl files are not provided to create a cwl workflow file. You can see that one of the inputs can come from a dataset but two need to be provided by the user. This example showcases the discovery functionality of the tool as it gives an example of two inputs that would require a different dataset or manual input in order to derive the parameter of interest.\n",
    "\n",
    "\n",
    "**3. Provide additional information to link inputs and outputs from cwl files**\n",
    "\n",
    "In order to assemble the workflow into a cwl file, the knowledge graph pull the cwl tool files and read the information they contain. The json description of the tools are simplified contextual description allowing a human understanding of the tool function. However, the cwl file embed more complex information and require some manual inputs to link their more complex inputs and outputs. You are therefore prompt with several questions. The idea is, if needed, to link the input(s) and output(s) of workflow steps. \n",
    "\n",
    "Let's analyse example 1:\n",
    "The example contains two steps: \n",
    "1- Dataset ID, Version ID -> tool_extract_indep_var_sds -> x_file\n",
    "2- x_file -> tool_extract_dep_var_sds -> y_file\n",
    "\n",
    "We are first asked if any link need to be created between step 2 outputs and step 1 input. In that case, yes, x_file and x_file represents the same object and should be linked.\n",
    "Answers: \n",
    "Does any input of current step need to be linked to a previous output (yes/no): yes\n",
    "Input_name: x_file (corresponds to the input of step 2)\n",
    "Output_name: x_file (corresponds to the output of step 1)\n",
    "\n",
    "There is no other link to create (enter 'no'). There is no duplicate between steps inputs so no action is needed. In case you had common inputs you can choose if they represent the same object, if they do not, their names will be indexed with the tool name.\n",
    "\n",
    "\n",
    "**4. Provide a workflow name and save**\n",
    "\n",
    "Finally, provide a name for the workflow you assembled without specifying an extension. For example: 'example_1_workflow'. \n",
    "A cwl file containing the workflow information will be saved in your current working directory under workflows/. You now have access to a standardised description of the workflow of your choice that can derive your parameter of interest.\n",
    "\n",
    "Only example 1 can be saved as the example 2 does not contain the cwl file for the tool and model which is necessary for writing the workflow into a cwl file."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c5d020732d98d2cc"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Saving the workflow in SDS\n",
    "The workflow can be saved in the SDS format. The SDS format is a standardised format that can be used to share workflows between different platforms and make the workflow FAIR. The SDS format is a json file that contains the information of the workflow in a structured way. You can convert the workflow to SDS by running the following code (in this jupyter notebook):"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4e9411da36a913e2"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "!pip install sparc-me"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bc91d8867b011d33"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import shutil\n",
    "from sparc_me import Dataset"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "55978276fd01eb23"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "workflow_name = \"example_1_workflow.cwl\"\n",
    "dataset = Dataset()\n",
    "dataset.load_dataset(from_template=True, version=\"2.0.0\")\n",
    "dataset.save(save_dir=\"./sds\")\n",
    "shutil.copy('workflows/' + workflow_name, \"./sds/primary/\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3ce3c7c115ed0c0e"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Note: change the workflow name to the one you saved in the previous step."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1d9245df0741107b"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Running the workflow\n",
    "Your workflow is now saved in the SDS format. To run it, have a look at tutorial 6."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "86d67243a8313660"
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
